spring.application.name=agent

# For OTLP - OTLP Prometheus endpoint, OTLP requires pushing
management.otlp.metrics.export.url=http://localhost:9090/api/v1/otlp/v1/metrics
# only for demo purposes
management.otlp.metrics.export.step=2s
# All traces should be sent to latency analysis tool
management.tracing.sampling.probability=1.0
# OTLP endpoint - OTLP Tempo endpoint
management.zipkin.tracing.endpoint=http://localhost:4318/v1/traces
management.zipkin.tracing.encoding=PROTO3

# For Exemplars to work we need histogram buckets - TODO: Micrometer OTLP doesn't yet support exemplars
management.metrics.distribution.percentiles-histogram.http.server.requests=true

spring.ai.openai.base-url=http://localhost:12434/engines
spring.ai.openai.api-key=test
spring.ai.openai.chat.options.model=ai/llama3.1
spring.ai.openai.chat.options.temperature=0.7
spring.ai.openai.chat.options.max-tokens=2048


spring.ai.openai.embedding.options.model=ai/mxbai-embed-large
spring.ai.vectorstore.pgvector.initialize-schema=true
spring.ai.vectorstore.pgvector.collection-name=test


spring.datasource.url=jdbc:postgresql://localhost:5432/agent
spring.datasource.username=agent
spring.datasource.password=agent